import os
os.environ["PATH"] += r";D:\ffmpeg\ffmpeg-2025-12-07-git-c4d22f2d2c-full_build\bin"
import json
import whisper  # å¯¼å…¥æœ¬åœ° Whisper åº“
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()

# 1. åˆå§‹åŒ–ç¡…åŸºæµåŠ¨ API å®¢æˆ·ç«¯ (ç”¨äº LLM)
client = OpenAI(
    api_key=os.getenv("OPENAI_API_KEY"),
    base_url=os.getenv("OPENAI_BASE_URL")
)

# 2. åŠ è½½æœ¬åœ° Whisper æ¨¡å‹ (æ‡’åŠ è½½ï¼Œç¬¬ä¸€æ¬¡è°ƒç”¨æ—¶æ‰ä¼šä¸‹è½½æ¨¡å‹)
# "base" æ¨¡å‹é€Ÿåº¦å¿«ä¸”ç²¾åº¦å°šå¯ï¼›å¦‚æœç”µè„‘é…ç½®å¥½å¯ç”¨ "small" æˆ– "medium"
print("â³ æ­£åœ¨åŠ è½½æœ¬åœ° Whisper æ¨¡å‹ (é¦–æ¬¡è¿è¡Œä¼šä¸‹è½½ ~140MB)...")
whisper_model = whisper.load_model("base") 

def transcribe_audio(audio_path):
    """
    ä½¿ç”¨æœ¬åœ° Whisper æ¨¡å‹å°†éŸ³é¢‘è½¬ä¸ºå¸¦æ—¶é—´æˆ³çš„æ–‡å­—
    """
    print(f"ğŸ¤ æ­£åœ¨æœ¬åœ°è½¬å½•éŸ³é¢‘: {audio_path} ...")
    
    # è°ƒç”¨æœ¬åœ°æ¨¡å‹è¿›è¡Œè½¬å½•
    result = whisper_model.transcribe(audio_path)
    
    # Whisper æœ¬åœ°åº“è¿”å›çš„ segments æ ¼å¼æœ¬èº«å°±æ˜¯ list of dict
    return result['segments']

def analyze_segments(segments):
    """
    è°ƒç”¨ç¡…åŸºæµåŠ¨å¤§æ¨¡å‹ (DeepSeek/Qwen) åˆ†æå“ªäº›ç‰‡æ®µéœ€è¦ä¿ç•™
    """
    print("ğŸ§  æ­£åœ¨è¯·æ±‚ç¡…åŸºæµåŠ¨ (DeepSeek) åˆ†æå‰ªè¾‘æ–¹æ¡ˆ ...")
    
    # ç®€åŒ–ä¸€ä¸‹æ•°æ®å‘é€ç»™ LLMï¼ŒèŠ‚çœ token
    simple_segments = [
        {"start": round(s['start'], 2), "end": round(s['end'], 2), "text": s['text'].strip()} 
        for s in segments
    ]
    input_text = json.dumps(simple_segments, ensure_ascii=False)

    system_prompt = """
    ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è§†é¢‘å‰ªè¾‘å¸ˆã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®å­—å¹•æ—¶é—´æˆ³ï¼Œå»é™¤"æ— æ„ä¹‰çš„åºŸè¯"ã€"é‡å¤å•°å—¦"ã€"å£è¯¯"ä»¥åŠ"é•¿æ—¶é—´é™é»˜"çš„ç‰‡æ®µã€‚
    
    ã€è¾“å…¥ã€‘ä¸€æ®µè§†é¢‘çš„å­—å¹•åˆ—è¡¨ JSONã€‚
    ã€è¾“å‡ºã€‘ä¸¥æ ¼çš„ JSON æ ¼å¼ï¼ŒåŒ…å«ä¸€ä¸ª "keep_ranges" åˆ—è¡¨ï¼Œä»£è¡¨éœ€è¦**ä¿ç•™**çš„æ—¶é—´æ®µï¼ˆç§’ï¼‰ã€‚
    
    è§„åˆ™ï¼š
    1. ä¿ç•™æ ¸å¿ƒä¿¡æ¯ï¼Œåˆ‡é™¤ "å‘ƒã€é‚£ä¸ªã€å°±æ˜¯" ç­‰å¡«å……è¯ã€‚
    2. å¦‚æœæœ‰è‡ªæˆ‘ä¿®æ­£ï¼ˆå¦‚"æˆ‘æƒ³è¦...æˆ‘å¸Œæœ›"ï¼‰ï¼Œåªä¿ç•™ä¿®æ­£åçš„ç‰ˆæœ¬ã€‚
    3. åˆå¹¶ç›¸é‚»çš„ä¿ç•™ç‰‡æ®µï¼Œé¿å…è¿‡åº¦ç»†ç¢çš„å‰ªè¾‘ã€‚
    4. è¾“å‡ºæ ¼å¼å¿…é¡»ä¸º: {"keep_ranges": [[0, 5.2], [8.4, 15.0]]}
    """

    try:
        # è·å– .env é‡Œé…ç½®çš„æ¨¡å‹åå­—
        model_name = os.getenv("LLM_MODEL_NAME", "deepseek-ai/DeepSeek-V2.5")
        
        response = client.chat.completions.create(
            model=model_name,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": input_text}
            ],
            response_format={"type": "json_object"}, # ç¡®ä¿è¿”å› JSON
            temperature=0.1 # æ¸©åº¦ä½ä¸€ç‚¹ï¼Œä¿è¯è¾“å‡ºç¨³å®š
        )
        
        content = response.choices[0].message.content
        result = json.loads(content)
        
        # ç®€å•çš„å®¹é”™å¤„ç†
        if "keep_ranges" not in result:
            print("âš ï¸ LLM è¿”å›æ ¼å¼å¼‚å¸¸ï¼Œå°è¯•ä¿®å¤...")
            # å¦‚æœæ¨¡å‹æ²¡è¿”å› keep_rangesï¼Œè¿™é‡Œå¯ä»¥åŠ å…œåº•é€»è¾‘ï¼Œæ¯”å¦‚è¿”å›åŸè§†é¢‘
            return [[0, segments[-1]['end']]]
            
        return result['keep_ranges']
        
    except Exception as e:
        print(f"âŒ LLM è°ƒç”¨å¤±è´¥: {e}")
        # å¦‚æœæŠ¥é”™ï¼Œä¸ºäº†ä¸è®©ç¨‹åºå´©æºƒï¼Œè¿”å›å…¨ç‰‡ä¿ç•™
        return [[0, segments[-1]['end']]]